---
title: "DA101 - Final project assignment"
author: "Wilson Le"
date: "10/21/2020"
output: 
  html_document:
    code_folding: hide
---

THE EFFECTS OF CLIMATE ON THE SPREAD OF COVID-19
===

## Data processing

Import libraries
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(GGally)
```

<br/><br/>

Import data:
```{r}
Covid19Data <- read.csv('Covid-19-All-State-History.csv')
maxTempData <- read.csv('./csv/tMax_US.csv')
minTempData <- read.csv('./csv/tMin_US.csv')
windData <- read.csv('./csv/wind_US.csv')
stateData <- read.csv('./csv/states.csv')
```

<br/><br/>

Process Covid19 data:


```{r}
Covid19Data <- Covid19Data %>%
  
  # Select the wanted variables:
  select(date, state, positiveCasesViral, totalTestsPeopleViral) %>%
  
  # Remove incomplete observations:
  na.omit() %>%
  
  # Filter out data within January and August
  filter(as.numeric(substr(date, start = 6, stop = 7)) <= 8) %>% 
  
  # Mutate a month variable
  mutate(month = substr(date, start = 1, stop = 7))
  
# Aggregate monthly sum positive case of each state:
monthlySumPositiveCase <- aggregate(Covid19Data$positiveCasesViral, by=list(state=Covid19Data$state, month = Covid19Data$month), FUN=sum) %>% rename(positiveCaseViral = x)

# Aggregate monthly sum tests of each state:
monthlySumTests <- aggregate(Covid19Data$totalTestsPeopleViral, by=list(state=Covid19Data$state, month = Covid19Data$month), FUN=sum) %>% rename(totalTestsPeopleViral = x)

# Merge the two together:
Covid19MonthlyData <- merge(monthlySumPositiveCase, monthlySumTests, by=c("state", "month"))


#Aggregate monthly conducted test of entire US:
Covid19SumTest <- aggregate(Covid19Data$totalTestsPeopleViral, by=list(month = Covid19Data$month), FUN=sum) %>% rename(totalTestPeopleViral = x)

kable(head(Covid19MonthlyData, n=20))
```

<br/><br/>

Process max temperature data:
```{r}
# Calculate the mean maximum temperature of a state in a day
maxTempbyProv <- aggregate(maxTempData[12:269] , by=list(province=maxTempData$Province_State), FUN=mean)

# Calculate the mean maximum temperature of a state in a month
maxTempbyProv <- maxTempbyProv %>%
  mutate("2020-01" = rowMeans(.[2:32])) %>%
  mutate("2020-02" = rowMeans(.[33:61])) %>%
  mutate("2020-03" = rowMeans(.[62:92])) %>%
  mutate("2020-04" = rowMeans(.[93:121])) %>%
  mutate("2020-05" = rowMeans(.[122:152])) %>%
  mutate("2020-06" = rowMeans(.[153:182])) %>%
  mutate("2020-07" = rowMeans(.[183:213])) %>%
  mutate("2020-08" = rowMeans(.[214:244]))

# Select just the state and the mean maximum temperature of states in a month.
maxTempbyProv <- maxTempbyProv %>% select(province, starts_with("2020"))

# Define function to transpose a state's temperature per month data.
transposeMaxState <- function(stateName){
  df <- maxTempbyProv %>% filter(province == as.character(stateName)) %>%
    select(starts_with("2020")) %>%
    t() %>%
    as.data.frame()
  df <- df %>% mutate(month = rownames(df)) %>% mutate(province = stateName) %>% rename(Max = V1)
  return(df)
}

# Define function to bind all the transposed data.
bindStates <- function(){
  bindDf <- data.frame()
  for (state in maxTempbyProv$province){
    tempDf <- transposeMaxState(state)
    bindDf <- rbind(bindDf, tempDf)
  }
  return(bindDf)
}

# Transposed maximum temperature data
maxTempbyProvTransposed <- bindStates()

#Display the first 10 value of the new data set.
kable(head(maxTempbyProvTransposed, n=20))
```

<br/><br/>

Process min temperature data:
```{r}
#Calculate the mean minimum temperature of a state in a day
minTempbyProv <- aggregate(minTempData[12:269] , by=list(province=minTempData$Province_State), FUN=mean)

#Calculate the mean minimum temperature of a state in a month
minTempbyProv <- minTempbyProv %>%
  mutate("2020-01" = rowMeans(.[2:32])) %>%
  mutate("2020-02" = rowMeans(.[33:61])) %>%
  mutate("2020-03" = rowMeans(.[62:92])) %>%
  mutate("2020-04" = rowMeans(.[93:121])) %>%
  mutate("2020-05" = rowMeans(.[122:152])) %>%
  mutate("2020-06" = rowMeans(.[153:182])) %>%
  mutate("2020-07" = rowMeans(.[183:213])) %>%
  mutate("2020-08" = rowMeans(.[214:244]))

# Select just the state and the mean maximum temperature of states in a month.
minTempbyProv <- minTempbyProv %>% select(province, starts_with("2020"))

# Define function to transpose a state's temperature per month data.
transposeMinState <- function(stateName){
  df <- minTempbyProv %>% filter(province == as.character(stateName)) %>%
    select(starts_with("2020")) %>%
    t() %>%
    as.data.frame()
  df <- df %>% mutate(month = rownames(df)) %>% mutate(province = stateName) %>% rename(Min = V1)
  return(df)
}

# Define function to bind all the transposed data.
bindStates <- function(){
  bindDf <- data.frame()
  for (state in minTempbyProv$province){
    tempDf <- transposeMinState(state)
    bindDf <- rbind(bindDf, tempDf)
  }
  return(bindDf)
}

# Transposed maximum temperature data
minTempbyProvTransposed <- bindStates()

#Display the first 10 value of the new data set.
kable(head(minTempbyProvTransposed, n=20))
```

<br/><br/>

Process wind data:
```{r}
#Filter out invalid values:
windDataFiltered <- windData %>% filter_at(vars(starts_with("X")), all_vars(. > 0))

#Calculate the mean minimum temperature of a state in a day
windByProv <- aggregate(windDataFiltered[12:269] , by=list(province=windDataFiltered$Province_State), FUN=mean)

#Calculate the mean minimum temperature of a state in a month
windByProv <- windByProv %>%
  mutate("2020-01" = rowMeans(.[2:32])) %>%
  mutate("2020-02" = rowMeans(.[33:61])) %>%
  mutate("2020-03" = rowMeans(.[62:92])) %>%
  mutate("2020-04" = rowMeans(.[93:121])) %>%
  mutate("2020-05" = rowMeans(.[122:152])) %>%
  mutate("2020-06" = rowMeans(.[153:182])) %>%
  mutate("2020-07" = rowMeans(.[183:213])) %>%
  mutate("2020-08" = rowMeans(.[214:244]))

# Select just the state and the mean maximum temperature of states in a month.
windByProv <- windByProv %>% select(province, starts_with("2020"))

# Define function to transpose a state's temperature per month data.
transposeWinState <- function(stateName){
  df <- windByProv %>% filter(province == as.character(stateName)) %>%
    select(starts_with("2020")) %>%
    t() %>%
    as.data.frame()
  df <- df %>% mutate(month = rownames(df)) %>% mutate(province = stateName) %>% rename(Wind = V1)
  return(df)
}

# Define function to bind all the transposed data.
bindStates <- function(){
  bindDf <- data.frame()
  for (state in windByProv$province){
    tempDf <- transposeWinState(state)
    bindDf <- rbind(bindDf, tempDf)
  }
  return(bindDf)
}

# Transposed maximum temperature data
windByProvTransposed <- bindStates()

#Display the first 10 value of the new data set.
kable(head(windByProvTransposed, n=20))
```

<br/><br/>

Merge temperature and wind data:

```{r warning=FALSE, message=FALSE}
# Merge the max and min temperature into one data set.
TempByProv <- merge(maxTempbyProvTransposed, minTempbyProvTransposed, by = c("province", "month"))
ClimateByProv <- merge(TempByProv, windByProvTransposed, by = c("province", "month"))
# Display the first 10 values of the merged temperature data set.
options(digits = 3)
kable(head(ClimateByProv, n = 10))
```

<br/><br/>

Merge temperature data with Covid19 data:
```{r warning=FALSE, message=FALSE}
ClimateByState <- merge(ClimateByProv, stateData, by=c("province"))
Covid19Climate <- merge(ClimateByState, Covid19MonthlyData, by=c("state", "month"))

# Display the first 10 values of the merged temperature data set.
options(digits = 3)
kable(head(Covid19Climate, n = 10))
```

Written Analysis
A knitted and polished rMarkdown file and HTML output reporting the results of your final data analysis project. Roughly, 3-5 written pages maximum. Consider it a "final takeaway" of all the skills you’ve learned in class over the semester. Below is a rough structure of your final written report. Here you should use code folding so this section mirrors a ready to deliver report with clear section headers and interpretations of any statistical or graphical output (like several of our previous projects), but it will also be easy for your instructor to see the code, if needed. Include the following sections in your report:

## Introduction:

_Provide a two paragraph introduction, professionally written, that gives an overview of the essentials someone needs to know to make sense of the data you show. You must cite and link to your data set somewhere in the introduction (a footnote is OK). Revising and building on your introduction from the previous assignments is allowed and encouraged, but using the exact same introduction is discouraged._

Corona virus disease 2019 (COVID-19), initially identified in December 2019 in Wuhan, China, has now become a global pandemic. It is a very infectious virus that spreads between humans, mainly via physical contact with bodily fluids[1]. Scientific research has shown that climate temperature plays a role in the spreading of the virus[2]. This research aim to redo the experiment using different data and techniques to see if the claims made in the researches are true.

Research will try to answer the question: Does climate temperature affects the spread of Covid-19? And how? The dependent variable, which will be the variable used to determine the "spread of Covid-19", will be the daily confirmed cases of a country. By looking at a single country, the data will be more uniform as different country has different population size and different seriousness when it comes to response to the pandemic, which consequently affect the number of confirmed cases. This variable will be extracted from the Covid-19 data by Out world in Data[4]. The independent variable that might effect the spread of Covid-19 that the research is going to look at is minimum and maximum temperature of different regions in a country (i.e different states in the US). Temperature data set of the US states since January to October[5] will be used to extract the necessary data to perform analysis. The topic question will be an exploratory type of question, as it will be looking for unknown patterns within the data.

## Ethical Considerations:

_Provide one paragraph discussing the stakeholders in your data analysis and your ethical concerns or responsibilities using the data and in your analysis. Everyone has ethical considerations, no matter what the data set or subject matter._

Since the researching the research is using data from the internet for analysis, the data itself are public for every one to look at and process. However, the research is conducted by an individual (me), however carefully conducted, there will be flaws and mistakes in logic and assumptions. There are potential for harm in this analysis. As Covid19 is a very unpredictable infectious disease, these analysis should only be part of the consideration of your decision to act upon the disease.

## Data Explanation and Exploration:

_Provide some details describing the data you are working with. What are the observations? The key variables you will be looking at? Are there any particular challenges in the data you will need to work through or be aware of during analysis?_

_Provide two polished visuals that describes the data in a way relevant to your question (descriptive, not related to your statistical model specifically--not a scatter plot). Write text that describes the data and what the visuals tell you about your data or decisions you will need to make for the analysis._

As stated above, the research will be looking at the spread of Covid-19, which is determined by the number of confirmed positive test cases in the states. The variables that might affect the spread are the temperature of the states.

The dependent variable will be taken from the COVID tracking project’s data set. The project is a non-profit organization tasked to collect and publish data required to quantify the spread and seriousness of COVID-19 in the United States. The data is now being collected by volunteers and processed and analyzed by developers, scientists, designers, editors, reporters, and many enthusiast contributors[5]. Despite being collected by volunteers, there are strict quality scoring methods in place for all these collected data. This project has been collecting data since January of 2020. With the vast amount of data and its precision, this data set samples the real situation of any collected regions. There are many variables in this data set, but this research only pays attention to a few of them. The “date” and “state” are 2 necessary variables to tell when and where the data is collected, along with the number that we are looking for, the “positiveCasesViral” and “totalTestsPeopleViral”. According to the metadata provided by the data owners, the variable “positiveCasesViral” corresponds to “the total number of unique people with a complete PCR test that returns positive”, or in other words, the total of confirmed cases, and the variable “totalTestsPeopleViral” corresponds to the total number of “unique people tested at least once via PCR testings”[6]. These 4 variables from this data set will provide data of confirmed cases in each state over a time period, which consequently corresponds to the spread of the pandemic in state areas of the whole country.

Moving on to the two independent variables, the data set collected by Eeemonts on Kaggle will provide precise data. This data set is actually compiled by calling API requests from Dark Sky, a company that’s recently acquired by Apple but the API data collection is still available. This company measures weather information and updates it by the minute[7]. Eeemonts has been pulling and compiling data since January 2020, resulting in a massive cluster of data sets that includes a multitude of variables[5]. The sample that this cluster of data sets is a detailed data weather information of every city of state every day since January. However, we are only paying attention to two data sets, the “tMax_US.csv” and “tMin_US.csv”. These data sets include two important variables that the research needs: the maximum temperature and the minimum temperature of a city in a state in a day, which, will provide the range of temperature of a state.

The challenge is that these two data set are formatted differently, so data wrangling is a challenge step, in order to produce a neat and usable data set for analysis. The Covid19 Data has more rows than columns, as the "Date" and "State" variable has its own column, meaning that for the number of rows will be the product of the number of states and the number of dates, resulting in more rows than columns. As for the temperature data set, there is more columns than rows. This is because instead of having a column specifically for dates, the data set is formatted so that every day has its own columns, and the intersection between the date and the state will be the temperature value. This means that the number of rows will be equal to the number of states, but the number of columns will be as many as the number of days, resulting in a data that has more columns than rows. To deal with this is a challange, as I have to transpose the temperature data and wrote my own function to turn it into the same format as the Covid-19 data. Only then can I merge the two data set together and start with my data exploration and analysis.

Bar plot showing the change in __number of positive test cases.__ in the entire US in 2020.
```{r}
#Aggregate monthly sum test of entire US:
Covid19SumPos <- aggregate(Covid19Climate$positiveCaseViral, by=list(month = Covid19Climate$month), FUN=sum) %>% rename(positiveCaseViral = x)

#Plot
ggplot(Covid19SumPos, aes(month, positiveCaseViral)) + 
  geom_bar(stat="identity", fill="steelblue") +
  labs(
    title="Covid19 positive test cases",
    caption='The change in Covid19 positive test cases in the entire US in 2020',
    x="Month",
    y="Positive test cases") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))
```

Frequency polygon showing distribution of maximum and minimum temperature across all the states:
```{r}
ggplot(Covid19Climate) + 
  geom_freqpoly(bins = 40, aes(Max), color="red", size=3) +
  geom_freqpoly(bins = 40, aes(Min), color="steelblue", size=3) +
  labs(title="Maximum (red) and Minimum (blue) temperature across the states", 
    x="degrees Celcius",
    y="Count") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))
```

Boxplot showing distribution of maximum and minimum temperature across the months:
```{r}
ggplot(Covid19Climate) + 
  geom_boxplot(aes(month, Max), outlier.colour = "gray", fill="red") +
  geom_boxplot(aes(month, Min), outlier.colour = "gray", fill="steelblue") +
  labs(
    title="Distribution of max and min temperature across the months", 
    x="Month",
    y="degrees Celcius") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))
```

Checking for multicolinearity between min, max temperature, and wind speed:
```{r}
ggpairs(Covid19Climate, columns=c("Max", "Min", "Wind"))
```

## Statistical Analysis and Interpretation:

_Provide at least two distinct statistical models (for example; multivariate regression and/or t-test) that you interpret correctly and fully in the text. Report your results in a polished table (kable)._

_Provide at least three polished visuals that specifically support and validate the model(s) you have developed (e.g., residual and regression line/scatter, histogram showing normality of data or residuals, etc.), or help to communicate your main result. Visuals should have captions and be referred to clearly in your text, and they should not all be the same (e.g., not three scatter plots). Text should fully explain what you show and your findings, to someone who is unfamiliar with your data, code, and models, in terms of the data and in plain language._

```{r warning=FALSE, message=FALSE}
train_test <- split(Covid19Climate, sample(0:107, size=2, replace=F))
test <- as.data.frame(train_test[2])
train <- as.data.frame(train_test[1])
colnames(test) <- colnames(Covid19Climate)
colnames(train) <- colnames(Covid19Climate)

maxTempModel <- lm(positiveCaseViral ~ Max, data=Covid19Climate)
minTempModel <- lm(positiveCaseViral ~ Min, data=Covid19Climate)
WindModel <- lm(positiveCaseViral ~ Wind, data=Covid19Climate)

summary(maxTempModel)
summary(minTempModel)
summary(WindModel)
```

As conducted in the data exploration part, the three maximum temperature, minimum temperature and wind speed has significant multicolinearity with each other, therefore causing major problems if multivariate regression is conducted. Thus I have conducted 3 separate linear regression to test for separate correlation between each independent variable and the dependent variable. These 3 linear regression model respectively describes the relationship between the number of positive test case based on maximum temperature, minimum temperature, and wind speed of each states over the months. Running the summary function on all 3 models gives us the general view of all 3 models. The values are the residuals and its statistical values (mean, mode, median, min, max), estimated coefficients and its standard errors, the R-squared metric, the F-value. 

The stars (***) are the significance level, computed and displayed based on the p-value of the model. Based on the summary, we can see that all three models level 2 or 3 significance, indicating that it's unlikely that no relationship exist between the number of positive test cases and climate values (minimum temperature, maximum temperature, wind speed).

As for the estimated coefficients, this value represents the slope of the function as calculated by the regression. In our 3 models, the estimated coefficients for maximum temperature, minimum temperature, wind speed, are respectively 109117, 123043, and -851230. In other words, for every increase of 1 degrees Celcius of maximum temperature, the predicted number of infected increase by 109117. For every increase of 1 degrees Celcius of minimum temperature, the predicted number of infected increase by 123043. For every increase of 1 meters per second of wind speed, the predicted number of infected decrease by 851230.

As the name of the value suggest, estimated coefficients has its errors in the estimation. The standard Error is the measure of the variance in the coefficient. In the three models, the standard errors are respectively 28422, 28093, 306391. The value for maximum and minimum temperature is roughly 5 times smaller than the estimated coefficient itself. The value for wind speed, however, is up to half the estimated coefficients.

R-squared is a metric used to evaluate the fit precision of the model. The maximum temperature, minimum temperature and the wind speed model all respectively has R-squared value of 12.3%, 15.4%, 6.85%. These values means that the model explains very few of the variance in the observation around the line of best fit.

The F-value in these models are the results of tests where the null hypothesis is "all of the regression coefficients are equal to zero". Since the p-value of all 3 models are much less than the alpha level, the null hypothesis can be rejected. All the models have their F-statistic relatively larger than 1, given the size of the data, insinuating that there may be correlations between the independent variables and the number of positive test cases in the US.


```{r warning=FALSE, message=FALSE}
test <- test %>%
  mutate(predictionWindDiff =  abs(positiveCaseViral - predict(WindModel, test))) %>%
  mutate(predictionMinDiff =  abs(positiveCaseViral - predict(minTempModel, test))) %>%
  mutate(predictionMaxDiff =  abs(positiveCaseViral - predict(maxTempModel, test)))
```

Histogram representing difference between predicted number of positive cases and actual positive cases:
```{r warning=FALSE, message=FALSE}
ggplot(test, aes(test$predictionMaxDiff)) + 
  geom_histogram(fill="steelblue") +
  labs(
    title="Distribution of maximum temperature prediction difference",
    caption="Histogram represents the distribution of the maximum temperature model's prediction difference",
    x="Confirmed cases difference") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))

ggplot(test, aes(test$predictionMinDiff)) + 
  geom_histogram(fill="steelblue") +
  labs(
    title="Distribution of minimum temperature prediction difference",
    caption="Histogram represents the distribution of the minimum temperature model's prediction difference",
    x="Confirmed cases difference") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))

ggplot(test, aes(test$predictionWindDiff)) + 
  geom_histogram(fill="steelblue") +
  labs(
    title="Distribution of wind speed prediction difference",
    caption="Histogram represents the distribution of the wind speed model's prediction difference",
    x="Confirmed cases difference") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))
```



## Conclusions:

_Provide one or two paragraphs concluding about the data: what does it tell us, what are the limitations to this data/model, and what is one future direction you could envision for future data analysts or data collectors?_

_Find at least one reference that is relevant to or supports your insights, and cite it in this section. You may cite a reference by linking directly to it in your Rmd and/or citing it using your style of choice. Either way, the full citation should also appear in a "Works Cited" page below the conclusions section._

This experiment was done with 





